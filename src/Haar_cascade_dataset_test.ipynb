{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n# ms-python.python added\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Using OpenCV Haar Cascade to detect faces\n","\n"," # Notes\n","\n"," Dataset: https://susanqq.github.io/UTKFace/\n","\n"," The labels of each face image is embedded in the file name, formated like [age]_[gender]_[race]_[date&time].jpg\n"," - [age] is an integer from 0 to 116, indicating the age\n"," - [gender] is either 0 (male) or 1 (female)\n"," - [race] is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).\n"," - [date&time] is in the format of yyyymmddHHMMSSFFF, showing the date and time an image was collected to UTKFace"],"metadata":{}},{"source":["import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","\n","# Change working directory from the workspace root to the ipynb file location.\n","try:\n","\tos.chdir(os.path.join(os.getcwd(), 'src'))\n","\tprint(os.getcwd())\n","except:\n","\tpass\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Base variables\n","training_file_path = '../resources/haarcascade_frontalface_default.xml'\n","faces_dataset_path = '../local_resources/UTKFace_cropped_aligned/'\n","complete_faces_dataset_path = '../local_resources/UTKFace_complete/'\n","haar_face_cascade = cv2.CascadeClassifier(training_file_path)\n","example_img_path = '../resources/test1.jpg'\n","example_img = cv2.imread(example_img_path)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Base functions\n","\n","def detect_faces(f_cascade, img, scaleFactor = 1.1):\n","    #just making a copy of image passed, so that passed image is not changed\n","    img_copy = img.copy()\n","    #convert the test image to gray image as opencv face detector expects gray images\n","    gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)       \n","    #let's detect multiscale (some images may be closer to camera than others) images\n","    faces = f_cascade.detectMultiScale(gray, scaleFactor=scaleFactor, minNeighbors=5)\n","    return faces\n","\n","# go over list of faces and draw them as rectangles on original colored img\n","def print_faces(img, faces):\n","    img_copy = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","        plt.figure()\n","    plt.imshow(img_copy)\n","    return\n","\n","def load_element_image(element):\n","    element[\"image\"] = cv2.imread(element[\"path\"])\n","    return element\n","\n","def detect_faces_from_element(element):\n","    element[\"faces\"] = detect_faces(haar_face_cascade, element[\"image\"])\n","    element[\"face_count\"] = len(element[\"faces\"])\n","    return element\n","\n","def filter_age(img_list, range_start, range_end):\n","    img_list[:] = [x for x in img_list if (range_start <= x[\"age\"] <= range_end)]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Run single image test\n","print_faces(example_img, detect_faces(haar_face_cascade, example_img))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Create a list of images\n","img_name_list = os.listdir(complete_faces_dataset_path)\n","img_name_list_small = img_name_list[:10]\n","img_list = []\n","start_time = time.time()\n","for img_name in img_name_list_small:\n","    img_name_split = img_name.split(\"_\")\n","    img_list.append({\n","        \"name\": img_name,\n","        \"path\": complete_faces_dataset_path + img_name,\n","        \"age\": int(img_name_split[0]),\n","        \"gender\": int(img_name_split[1]),\n","        \"race\": int(img_name_split[2])\n","    })\n","print(time.time() - start_time)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Filter list\n","filter_age(img_list, 18, 60)\n","print(len(img_list))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Load all images from the list\n","\n","start_time = time.time()\n","for img in img_list:\n","    load_element_image(img)\n","print(time.time() - start_time)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Detect faces from the list\n","   \n","start_time = time.time()\n","for img in img_list:\n","    detect_faces_from_element(img)\n","print(time.time() - start_time)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","for img in img_list:\n","    print(img[\"face_count\"])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}