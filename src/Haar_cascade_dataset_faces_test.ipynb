{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Haar_cascade_dataset_faces_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_WMu77hOZYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncoment this when running on google colab\n",
        "!apt-get -qq install -y libsm6 libxext6\n",
        "!pip install -q -U opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SFlUPLCM370",
        "colab_type": "text"
      },
      "source": [
        " Using OpenCV Haar Cascade to detect faces\n",
        "\n",
        " # Notes\n",
        "\n",
        " Dataset: https://susanqq.github.io/UTKFace/\n",
        "\n",
        " The labels of each face image is embedded in the file name, formated like [age]_[gender]_[race]_[date&time].jpg\n",
        " - [age] is an integer from 0 to 116, indicating the age\n",
        " - [gender] is either 0 (male) or 1 (female)\n",
        " - [race] is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).\n",
        " - [date&time] is in the format of yyyymmddHHMMSSFFF, showing the date and time an image was collected to UTKFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_JVeL33M371",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "# Change working directory from the workspace root to the ipynb file location.\n",
        "try:\n",
        "\tos.chdir(os.path.join(os.getcwd(), 'src'))\n",
        "\tprint(os.getcwd())\n",
        "except:\n",
        "\tpass\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk60RJ1QNHd0",
        "colab_type": "code",
        "outputId": "9845dde8-a329-48f1-ecb5-3e98618fea7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ve1kJbHM373",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base variables\n",
        "training_file_path = '/content/drive/My Drive/Documentos/UFABC/TG/haarcascade_frontalface_default.xml'\n",
        "faces_dataset_path_zip = '/content/drive/My Drive/Documentos/UFABC/TG/UTKFace_complete.tar.gz'\n",
        "faces_dataset_path = '/content/UTKFace_complete'\n",
        "haar_face_cascade = cv2.CascadeClassifier(training_file_path)\n",
        "example_img_path = '/content/drive/My Drive/Documentos/UFABC/TG/test1.jpg'\n",
        "example_img = cv2.imread(example_img_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4T5X4hwPAkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip dataset\n",
        "import tarfile\n",
        "tar = tarfile.open(faces_dataset_path_zip, \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IowJckgJTtGy",
        "colab_type": "code",
        "outputId": "5c369d84-56d1-423f-a730-8faff9758279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Check unzip\n",
        "print(len([name for name in os.listdir(faces_dataset_path)]))\n",
        "!ls /content/UTKFace_complete | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24108\n",
            "24108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbxl9s7j0SYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fix file names\n",
        "!mv /content/UTKFace_complete/39_1_20170116174525125.jpg /content/UTKFace_complete/39_1_0_20170116174525125.jpg\n",
        "!mv /content/UTKFace_complete/53__0_20170116184028385.jpg /content/UTKFace_complete/53_0_0_20170116184028385.jpg\n",
        "!mv /content/UTKFace_complete/61_3_20170109150557335.jpg /content/UTKFace_complete/61_3_0_20170109150557335.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ahK0Vg1M376",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base functions\n",
        "\n",
        "def detect_faces(f_cascade, img, scaleFactor = 1.1):\n",
        "    #just making a copy of image passed, so that passed image is not changed\n",
        "    img_copy = img.copy()\n",
        "    #convert the test image to gray image as opencv face detector expects gray images\n",
        "    gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)       \n",
        "    #let's detect multiscale (some images may be closer to camera than others) images\n",
        "    faces = f_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3, minSize=(30,30))\n",
        "    return faces\n",
        "\n",
        "# go over list of faces and draw them as rectangles on original colored img\n",
        "def print_faces(img, faces):\n",
        "    img_copy = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        plt.figure()\n",
        "    plt.imshow(img_copy)\n",
        "    return\n",
        "\n",
        "def load_element_image(element):\n",
        "  element[\"image\"] = cv2.imread(element[\"path\"])\n",
        "  return element\n",
        "\n",
        "def detect_faces_from_element(element):\n",
        "    element[\"faces\"] = detect_faces(haar_face_cascade, element[\"image\"])\n",
        "    element[\"face_count\"] = len(element[\"faces\"])\n",
        "    return element\n",
        "  \n",
        "def load_and_detect_faces(element):\n",
        "  element[\"face_count\"] = len(detect_faces(haar_face_cascade, cv2.imread(element[\"path\"])))\n",
        "\n",
        "def filter_age(img_list, range_start, range_end):\n",
        "    img_list[:] = [x for x in img_list if (range_start <= x[\"age\"] <= range_end)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00x7oYqsM37_",
        "colab_type": "code",
        "outputId": "7fd91338-b54b-4f4b-ce62-3240b67f4981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create a list of images\n",
        "img_name_list = os.listdir(faces_dataset_path)\n",
        "img_name_list.sort()\n",
        "#img_name_list = img_name_list[:10]\n",
        "img_list = []\n",
        "start_time = time.time()\n",
        "for img_name in img_name_list:\n",
        "  try:\n",
        "    img_name_split = img_name.split(\"_\")\n",
        "    img_list.append({\n",
        "        \"name\": img_name,\n",
        "        \"path\": faces_dataset_path + \"/\" + img_name,\n",
        "        \"age\": int(img_name_split[0]),\n",
        "        \"gender\": int(img_name_split[1]),\n",
        "        \"race\": int(img_name_split[2])\n",
        "    })\n",
        "  except:\n",
        "    print(img_name)\n",
        "print(time.time() - start_time)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1614546775817871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzPrMb_M38B",
        "colab_type": "code",
        "outputId": "b411e8e8-5028-4668-cdec-369f765923a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Filter list\n",
        "filter_age(img_list, 18, 60)\n",
        "count_imgs = len(img_list)\n",
        "print(count_imgs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT1bFqxKIgWm",
        "colab_type": "code",
        "outputId": "54fc2c54-e576-4c4a-9705-9d668bc60647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load and detect faces from the list\n",
        "   \n",
        "start_time = time.time()\n",
        "counter=0\n",
        "for img in img_list:\n",
        "    counter=counter+1\n",
        "    eta = (time.time() - start_time)*(count_imgs - counter)/counter\n",
        "    print(\"\\r\" + str(counter) + \" eta = \" + str(eta), end = ' ')\n",
        "    load_and_detect_faces(img)\n",
        "\n",
        "print(\" \")\n",
        "print(time.time() - start_time)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17130 eta = 0.0  \n",
            "3634.049448490143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2_8uTGM38I",
        "colab_type": "code",
        "outputId": "b0009428-c17a-4e54-e003-6dfee36ce496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "count_0=0\n",
        "count_1=0\n",
        "count_2=0\n",
        "for img in img_list:\n",
        "    if img[\"face_count\"] == 0:\n",
        "      count_0 += 1\n",
        "    elif img[\"face_count\"] == 1:\n",
        "      count_1 += 1\n",
        "    else:\n",
        "      count_2 += 1\n",
        "\n",
        "print(str(count_0) + \" images with 0 faces (\" + str(count_0*100/count_imgs) + \"%)\")\n",
        "print(str(count_1) + \" images with 1 faces (\" + str(count_1*100/count_imgs) + \"%)\")\n",
        "print(str(count_2) + \" images with 2 or more faces (\" + str(count_2*100/count_imgs) + \"%)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283 images with 0 faces (1.6520723876240513%)\n",
            "8789 images with 1 faces (51.30764740221833%)\n",
            "8058 images with 2 or more faces (47.04028021015762%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0ygH930ZEJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show n faces\n",
        "\n",
        "for img in img_list[:10]:\n",
        "  if img[\"face_count\"] > 0:\n",
        "    print_faces(cv2.imread(img[\"path\"]), img[\"faces\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Y7b7kJcPEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export results\n",
        "\n",
        "import json\n",
        "\n",
        "img_list_clean = []\n",
        "for img in img_list:\n",
        "  img_copy = img.copy()\n",
        "  #del img_copy[\"faces\"]\n",
        "  img_list_clean.append(img_copy)\n",
        "\n",
        "result = {\"raw_result\": img_list_clean}\n",
        "with open('result_faces_scaleFactor_105_minNeighbors_3_minSize_30_30.json', 'w') as fp:\n",
        "    json.dump(result, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rvMwvhYpBMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/result_faces_scaleFactor_105_minNeighbors_3_minSize_30_30.json /content/drive/My Drive/Documentos/UFABC/TG/result_faces_scaleFactor_105_minNeighbors_3_minSize_30_30.json"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}